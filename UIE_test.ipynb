{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6JlnE4yLY2H",
        "outputId": "31fc07dd-b0ce-4df4-925d-9b610c0a75c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UIE'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 334 (delta 3), reused 2 (delta 2), pack-reused 329 (from 1)\u001b[K\n",
            "Receiving objects: 100% (334/334), 153.51 KiB | 1.69 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "/content/UIE\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/universal-ie/UIE.git\n",
        "%cd UIE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSXrY00qRLYq",
        "outputId": "f4e031ed-8fc3-40a8-91c6-ca60ac074282"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==1.0.0 (from -r requirements.txt (line 1))\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting altair==4.2.0 (from -r requirements.txt (line 2))\n",
            "  Downloading altair-4.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting anyio==3.5.0 (from -r requirements.txt (line 3))\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting anytree==2.8.0 (from -r requirements.txt (line 4))\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting argon2-cffi==21.3.0 (from -r requirements.txt (line 5))\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (21.2.0)\n",
            "Collecting asgiref==3.5.0 (from -r requirements.txt (line 7))\n",
            "  Downloading asgiref-3.5.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting astor==0.8.1 (from -r requirements.txt (line 8))\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting asttokens==2.0.5 (from -r requirements.txt (line 9))\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting attrs==21.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting autopep8==1.6.0 (from -r requirements.txt (line 11))\n",
            "  Downloading autopep8-1.6.0-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
            "Collecting backports.zoneinfo==0.2.1 (from -r requirements.txt (line 13))\n",
            "  Downloading backports.zoneinfo-0.2.1.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.1/74.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting base58==2.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting black==21.12b0 (from -r requirements.txt (line 15))\n",
            "  Downloading black-21.12b0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting bleach==4.1.0 (from -r requirements.txt (line 16))\n",
            "  Downloading bleach-4.1.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting blinker==1.4 (from -r requirements.txt (line 17))\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.5/111.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cachetools==4.2.4 (from -r requirements.txt (line 18))\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting certifi==2021.10.8 (from -r requirements.txt (line 19))\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cffi==1.15.0 (from -r requirements.txt (line 20))\n",
            "  Downloading cffi-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting charset-normalizer==2.0.10 (from -r requirements.txt (line 21))\n",
            "  Downloading charset_normalizer-2.0.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click==8.0.3 (from -r requirements.txt (line 22))\n",
            "  Downloading click-8.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting colorama==0.4.4 (from -r requirements.txt (line 23))\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting colorlog==6.6.0 (from -r requirements.txt (line 24))\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting commonmark==0.9.1 (from -r requirements.txt (line 25))\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting conllu==4.4.1 (from -r requirements.txt (line 26))\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting cycler==0.11.0 (from -r requirements.txt (line 27))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting dataclasses==0.6 (from -r requirements.txt (line 28))\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting datasets==1.9.0 (from -r requirements.txt (line 29))\n",
            "  Downloading datasets-1.9.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting debugpy==1.5.1 (from -r requirements.txt (line 30))\n",
            "  Downloading debugpy-1.5.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 31))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.7.1)\n",
            "Collecting dill==0.3.4 (from -r requirements.txt (line 33))\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting elasticsearch==7.16.3 (from -r requirements.txt (line 34))\n",
            "  Downloading elasticsearch-7.16.3-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting entrypoints==0.3 (from -r requirements.txt (line 35))\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting executing==0.8.2 (from -r requirements.txt (line 36))\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting faiss-cpu==1.7.2 (from -r requirements.txt (line 37))\n",
            "  Downloading faiss_cpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting fastapi==0.74.1 (from -r requirements.txt (line 38))\n",
            "  Downloading fastapi-0.74.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting filelock==3.0.12 (from -r requirements.txt (line 39))\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting fire==0.4.0 (from -r requirements.txt (line 40))\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fonttools==4.28.5 (from -r requirements.txt (line 41))\n",
            "  Downloading fonttools-4.28.5-py3-none-any.whl.metadata (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2022.1.0 (from -r requirements.txt (line 42))\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting future==0.18.2 (from -r requirements.txt (line 43))\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git-python==1.0.3 (from -r requirements.txt (line 44))\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Collecting gitdb==4.0.9 (from -r requirements.txt (line 45))\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl.metadata (998 bytes)\n",
            "Collecting GitPython==3.1.26 (from -r requirements.txt (line 46))\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting google-auth==2.3.3 (from -r requirements.txt (line 47))\n",
            "  Downloading google_auth-2.3.3-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting google-auth-oauthlib==0.4.6 (from -r requirements.txt (line 48))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting googleapis-common-protos==1.54.0 (from -r requirements.txt (line 49))\n",
            "  Downloading googleapis_common_protos-1.54.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting grpcio==1.43.0 (from -r requirements.txt (line 50))\n",
            "  Downloading grpcio-1.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting h11==0.13.0 (from -r requirements.txt (line 51))\n",
            "  Downloading h11-0.13.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting h5py==3.6.0 (from -r requirements.txt (line 52))\n",
            "  Downloading h5py-3.6.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting huggingface-hub==0.0.8 (from -r requirements.txt (line 53))\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting idna==3.3 (from -r requirements.txt (line 54))\n",
            "  Downloading idna-3.3-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting importlib-metadata==4.10.1 (from -r requirements.txt (line 55))\n",
            "  Downloading importlib_metadata-4.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting importlib-resources==5.4.0 (from -r requirements.txt (line 56))\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting iniconfig==1.1.1 (from -r requirements.txt (line 57))\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting ipykernel==6.7.0 (from -r requirements.txt (line 58))\n",
            "  Downloading ipykernel-6.7.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (7.34.0)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (0.2.0)\n",
            "Collecting ipywidgets==7.6.5 (from -r requirements.txt (line 61))\n",
            "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting jedi==0.18.1 (from -r requirements.txt (line 62))\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (0.42.1)\n",
            "Collecting Jinja2==3.0.3 (from -r requirements.txt (line 64))\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting joblib==1.1.0 (from -r requirements.txt (line 65))\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jsonschema==4.4.0 (from -r requirements.txt (line 66))\n",
            "  Downloading jsonschema-4.4.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting jupyter-client==7.1.1 (from -r requirements.txt (line 67))\n",
            "  Downloading jupyter_client-7.1.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting jupyter-core==4.9.1 (from -r requirements.txt (line 68))\n",
            "  Downloading jupyter_core-4.9.1-py3-none-any.whl.metadata (870 bytes)\n",
            "Collecting jupyterlab-pygments==0.1.2 (from -r requirements.txt (line 69))\n",
            "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl.metadata (329 bytes)\n",
            "Collecting jupyterlab-widgets==1.0.2 (from -r requirements.txt (line 70))\n",
            "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting kiwisolver==1.3.2 (from -r requirements.txt (line 71))\n",
            "  Downloading kiwisolver-1.3.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting Markdown==3.3.6 (from -r requirements.txt (line 72))\n",
            "  Downloading Markdown-3.3.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting MarkupSafe==2.0.1 (from -r requirements.txt (line 73))\n",
            "  Downloading MarkupSafe-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting matplotlib==3.5.1 (from -r requirements.txt (line 74))\n",
            "  Downloading matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting matplotlib-inline==0.1.3 (from -r requirements.txt (line 75))\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl.metadata (397 bytes)\n",
            "Collecting mistune==0.8.4 (from -r requirements.txt (line 76))\n",
            "  Downloading mistune-0.8.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting multiprocess==0.70.12.2 (from -r requirements.txt (line 77))\n",
            "  Downloading multiprocess-0.70.12.2-py39-none-any.whl.metadata (6.9 kB)\n",
            "Collecting mypy-extensions==0.4.3 (from -r requirements.txt (line 78))\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting nbclient==0.5.10 (from -r requirements.txt (line 79))\n",
            "  Downloading nbclient-0.5.10-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting nbconvert==6.4.0 (from -r requirements.txt (line 80))\n",
            "  Downloading nbconvert-6.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nbformat==5.1.3 (from -r requirements.txt (line 81))\n",
            "  Downloading nbformat-5.1.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting nest-asyncio==1.5.4 (from -r requirements.txt (line 82))\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting nltk==3.5 (from -r requirements.txt (line 83))\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting notebook==6.4.7 (from -r requirements.txt (line 84))\n",
            "  Downloading notebook-6.4.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting numpy==1.19.5 (from -r requirements.txt (line 85))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting oauthlib==3.1.1 (from -r requirements.txt (line 86))\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting packaging==21.3 (from -r requirements.txt (line 87))\n",
            "  Downloading packaging-21.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pandas==1.3.5 (from -r requirements.txt (line 88))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pandocfilters==1.5.0 (from -r requirements.txt (line 89))\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parso==0.8.3 (from -r requirements.txt (line 90))\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pathspec==0.9.0 (from -r requirements.txt (line 91))\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pexpect==4.8.0 (from -r requirements.txt (line 92))\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 93)) (0.7.5)\n",
            "Collecting Pillow==9.0.0 (from -r requirements.txt (line 94))\n",
            "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting platformdirs==2.4.1 (from -r requirements.txt (line 95))\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting pluggy==1.0.0 (from -r requirements.txt (line 96))\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting portalocker==2.3.2 (from -r requirements.txt (line 97))\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting prometheus-client==0.12.0 (from -r requirements.txt (line 98))\n",
            "  Downloading prometheus_client-0.12.0-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 99)) (2.3)\n",
            "Collecting prompt-toolkit==3.0.24 (from -r requirements.txt (line 100))\n",
            "  Downloading prompt_toolkit-3.0.24-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf==3.19.3 (from -r requirements.txt (line 101))\n",
            "  Downloading protobuf-3.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (806 bytes)\n",
            "Collecting psutil==5.9.0 (from -r requirements.txt (line 102))\n",
            "  Downloading psutil-5.9.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 103)) (0.7.0)\n",
            "Collecting pure-eval==0.2.1 (from -r requirements.txt (line 104))\n",
            "  Downloading pure_eval-0.2.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting py==1.11.0 (from -r requirements.txt (line 105))\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pyarrow==4.0.1 (from -r requirements.txt (line 106))\n",
            "  Downloading pyarrow-4.0.1.tar.gz (711 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m711.0/711.0 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFAHwMEgQVJN",
        "outputId": "318eb183-45aa-4a8b-e161-4b471f2ffc24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "\n",
        "!wget -q https://github.com/DAMO-NLP-SG/IE-E2H/archive/refs/heads/main.zip\n",
        "!unzip -q main.zip\n",
        "!mv IE-E2H-main/dataset_processing/converted_data/text2spotasoc/entity/conll03 ./conll03\n",
        "!rm -rf main.zip IE-E2H-main\n",
        "\n",
        "!mkdir output\n",
        "!mkdir hf_models\n",
        "!gdown 15OFkWw8kJA1k2g_zehZ0pxcjTABY2iF1 && unzip uie-large-en.zip -d hf_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqnSJMsoQ9iG",
        "outputId": "ec73820f-7440-48a8-cd5c-26dce4745ff2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15OFkWw8kJA1k2g_zehZ0pxcjTABY2iF1\n",
            "From (redirected): https://drive.google.com/uc?id=15OFkWw8kJA1k2g_zehZ0pxcjTABY2iF1&confirm=t&uuid=4edfe05b-ca96-4677-af71-6b54eaef8092\n",
            "To: /content/UIE/uie-large-en.zip\n",
            "100% 2.90G/2.90G [00:10<00:00, 272MB/s]\n",
            "Archive:  uie-large-en.zip\n",
            "   creating: hf_models/uie-large-en/\n",
            "  inflating: hf_models/uie-large-en/config.json  \n",
            "  inflating: hf_models/uie-large-en/special_tokens_map.json  \n",
            "  inflating: hf_models/uie-large-en/added_tokens.json  \n",
            "  inflating: hf_models/uie-large-en/spiece.model  \n",
            "  inflating: hf_models/uie-large-en/pytorch_model.bin  \n",
            "  inflating: hf_models/uie-large-en/tokenizer.json  \n",
            "  inflating: hf_models/uie-large-en/tokenizer_config.json  \n",
            "env: model_name=uie-large-en\n",
            "env: dataset_name=entity/conll03\n",
            "batch  8\n",
            "noise  0.1\n",
            "learning rate  1e-4\n",
            "warmup ratio  0.06\n",
            "label smoothing  0\n",
            "negative  -1\n",
            "Master Port: 14960\n",
            "Map Config config/offset_map/first_offset_en.yaml\n",
            "/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use-env is set by default in torchrun.\n",
            "If your script expects `--local-rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  main()\n",
            "W1117 11:40:13.176000 4426 torch/distributed/run.py:793] \n",
            "W1117 11:40:13.176000 4426 torch/distributed/run.py:793] *****************************************\n",
            "W1117 11:40:13.176000 4426 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W1117 11:40:13.176000 4426 torch/distributed/run.py:793] *****************************************\n",
            "2024-11-17 11:40:19.280659: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:40:19.280663: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:40:19.280665: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:40:19.280664: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:40:19.297106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:40:19.297112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:40:19.297112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:40:19.297115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:40:19.315267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:40:19.317113: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:40:19.317622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:40:19.317780: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:40:19.321835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:40:19.323261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:40:19.323727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:40:19.323957: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:40:19.337339: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:40:19.337339: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:40:19.337354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:40:19.337704: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:40:20.525533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-11-17 11:40:20.525717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-11-17 11:40:20.525740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-11-17 11:40:20.527073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "[rank1]: Traceback (most recent call last):\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 125, in resolve_trust_remote_code\n",
            "[rank1]:     answer = input(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 107, in _raise_timeout_error\n",
            "[rank1]:     raise ValueError(\n",
            "[rank1]: ValueError: Loading this dataset requires you to execute custom code contained in the dataset repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this dataset.\n",
            "\n",
            "[rank1]: During handling of the above exception, another exception occurred:\n",
            "\n",
            "[rank1]: Traceback (most recent call last):\n",
            "[rank1]:   File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "[rank1]:     main()\n",
            "[rank1]:   File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "[rank1]:     datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "[rank1]:     builder_instance = load_dataset_builder(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "[rank1]:     dataset_module = dataset_module_factory(\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1571, in dataset_module_factory\n",
            "[rank1]:     ).get_module()\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 761, in get_module\n",
            "[rank1]:     trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "[rank1]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "[rank1]:     raise ValueError(\n",
            "[rank1]: ValueError: The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "[rank1]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
            "[rank2]: Traceback (most recent call last):\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 125, in resolve_trust_remote_code\n",
            "[rank2]:     answer = input(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 107, in _raise_timeout_error\n",
            "[rank2]:     raise ValueError(\n",
            "[rank2]: ValueError: Loading this dataset requires you to execute custom code contained in the dataset repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this dataset.\n",
            "\n",
            "[rank2]: During handling of the above exception, another exception occurred:\n",
            "\n",
            "[rank2]: Traceback (most recent call last):\n",
            "[rank2]:   File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "[rank2]:     main()\n",
            "[rank2]:   File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "[rank2]:     datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "[rank2]:     builder_instance = load_dataset_builder(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "[rank2]:     dataset_module = dataset_module_factory(\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1571, in dataset_module_factory\n",
            "[rank2]:     ).get_module()\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 761, in get_module\n",
            "[rank2]:     trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "[rank2]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "[rank2]:     raise ValueError(\n",
            "[rank2]: ValueError: The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "[rank2]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
            "[rank3]: Traceback (most recent call last):\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 125, in resolve_trust_remote_code\n",
            "[rank3]:     answer = input(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 107, in _raise_timeout_error\n",
            "[rank3]:     raise ValueError(\n",
            "[rank3]: ValueError: Loading this dataset requires you to execute custom code contained in the dataset repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this dataset.\n",
            "\n",
            "[rank3]: During handling of the above exception, another exception occurred:\n",
            "\n",
            "[rank3]: Traceback (most recent call last):\n",
            "[rank3]:   File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "[rank3]:     main()\n",
            "[rank3]:   File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "[rank3]:     datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "[rank3]:     builder_instance = load_dataset_builder(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "[rank3]:     dataset_module = dataset_module_factory(\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1571, in dataset_module_factory\n",
            "[rank3]:     ).get_module()\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 761, in get_module\n",
            "[rank3]:     trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "[rank3]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "[rank3]:     raise ValueError(\n",
            "[rank3]: ValueError: The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "[rank3]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 125, in resolve_trust_remote_code\n",
            "[rank0]:     answer = input(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 107, in _raise_timeout_error\n",
            "[rank0]:     raise ValueError(\n",
            "[rank0]: ValueError: Loading this dataset requires you to execute custom code contained in the dataset repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this dataset.\n",
            "\n",
            "[rank0]: During handling of the above exception, another exception occurred:\n",
            "\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "[rank0]:     datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "[rank0]:     builder_instance = load_dataset_builder(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "[rank0]:     dataset_module = dataset_module_factory(\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1571, in dataset_module_factory\n",
            "[rank0]:     ).get_module()\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 761, in get_module\n",
            "[rank0]:     trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "[rank0]:     raise ValueError(\n",
            "[rank0]: ValueError: The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "[rank0]: Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
            "[rank0]:[W1117 11:40:44.011286533 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "[rank2]:[W1117 11:40:44.012110372 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "[rank1]:[W1117 11:40:44.013170748 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "[rank3]:[W1117 11:40:44.013734306 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "W1117 11:40:46.472000 4426 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4455 closing signal SIGTERM\n",
            "E1117 11:40:46.484000 4426 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 4456) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 208, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typing_extensions.py\", line 2853, in wrapper\n",
            "    return arg(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 204, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 189, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "run_uie_finetune.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2024-11-17_11:40:46\n",
            "  host      : f41b93c9c9fb\n",
            "  rank      : 1 (local_rank: 1)\n",
            "  exitcode  : 1 (pid: 4456)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "Map Config config/offset_map/first_offset_en.yaml\n",
            "data/text2spotasoc/entity/conll03/record.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run1/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run1/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run1/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run1/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run1/’: No such file or directory\n",
            "/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use-env is set by default in torchrun.\n",
            "If your script expects `--local-rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  main()\n",
            "W1117 11:40:49.984000 4693 torch/distributed/run.py:793] \n",
            "W1117 11:40:49.984000 4693 torch/distributed/run.py:793] *****************************************\n",
            "W1117 11:40:49.984000 4693 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W1117 11:40:49.984000 4693 torch/distributed/run.py:793] *****************************************\n",
            "W1117 11:40:52.388000 4693 torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGINT death signal, shutting down workers\n",
            "W1117 11:40:52.389000 4693 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4714 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 30, in <module>\n",
            "W1117 11:40:52.389000 4693 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4715 closing signal SIGINT\n",
            "    import transformers\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n",
            "    from . import dependency_versions_check\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
            "    from .utils.versions import require_version, require_version_core\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
            "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
            "W1117 11:40:52.390000 4693 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4716 closing signal SIGINT\n",
            "    from torch import Tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "W1117 11:40:52.390000 4693 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4717 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 30, in <module>\n",
            "    import transformers\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 10, in <module>\n",
            "        from torch._decomp import (from . import dependency_versions_check\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 250, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
            "    from .utils.versions import require_version, require_version_core\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
            "        from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schemaimport torch._refs\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 941, in <module>\n",
            "    from torch import Tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "    def sinh(a):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 475, in inner\n",
            "    def _ref(a: TensorLikeType) -> TensorLikeType:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 117, in __call__\n",
            "    sig = inspect.signature(fn)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3254, in signature\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 10, in <module>\n",
            "    from torch._decomp import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 250, in <module>\n",
            "    import torch._refs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 889, in <module>\n",
            "    def round(a: TensorLikeType, *, decimals: int = 0) -> TensorLikeType:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 191, in decomposition_decorator\n",
            "    pytree.tree_map_(register, aten_op)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py\", line 997, in tree_map_\n",
            "    tuple(map(func, *flat_args))  # consume and exhaust the iterable\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 188, in register\n",
            "    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 3002, in from_callable\n",
            "    _add_op_to_registry(registry, op, fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 64, in _add_op_to_registry\n",
            "    if torch._C._dispatch_has_kernel(op_overload.name()):\n",
            "KeyboardInterrupt\n",
            "    return _signature_from_callable(obj, sigcls=cls,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2463, in _signature_from_callable\n",
            "    return _signature_from_function(sigcls, obj,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2325, in _signature_from_function\n",
            "    parameters.append(Parameter(name, annotation=annotation,\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 2672, in __init__\n",
            "    if not name.isidentifier():\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 30, in <module>\n",
            "    import transformers\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n",
            "    from . import dependency_versions_check\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
            "    from .utils.versions import require_version, require_version_core\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
            "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
            "    from torch import Tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 10, in <module>\n",
            "    from torch._decomp import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 250, in <module>\n",
            "    import torch._refs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 1353, in <module>\n",
            "    def fmax(a: TensorLikeType, b: TensorLikeType) -> TensorLikeType:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 1030, in inner\n",
            "    def _ref(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 116, in __call__\n",
            "    def __call__(self, fn: Callable) -> Callable:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 30, in <module>\n",
            "    import transformers\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\", line 26, in <module>\n",
            "    from . import dependency_versions_check\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
            "    from .utils.versions import require_version, require_version_core\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
            "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
            "    from torch import Tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 10, in <module>\n",
            "    from torch._decomp import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 250, in <module>\n",
            "    import torch._refs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 1353, in <module>\n",
            "    def fmax(a: TensorLikeType, b: TensorLikeType) -> TensorLikeType:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_refs/__init__.py\", line 1030, in inner\n",
            "    def _ref(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 116, in __call__\n",
            "    def __call__(self, fn: Callable) -> Callable:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 208, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typing_extensions.py\", line 2853, in wrapper\n",
            "    return arg(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 204, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 189, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 260, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py\", line 137, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 696, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 855, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 4693 got signal: 2\n",
            "Map Config config/offset_map/first_offset_en.yaml\n",
            "data/text2spotasoc/entity/conll03/record.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run2/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run2/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run2/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run2/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run2/’: No such file or directory\n",
            "/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use-env is set by default in torchrun.\n",
            "If your script expects `--local-rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  main()\n",
            "W1117 11:40:56.234000 4791 torch/distributed/run.py:793] \n",
            "W1117 11:40:56.234000 4791 torch/distributed/run.py:793] *****************************************\n",
            "W1117 11:40:56.234000 4791 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W1117 11:40:56.234000 4791 torch/distributed/run.py:793] *****************************************\n",
            "W1117 11:40:56.834000 4791 torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGINT death signal, shutting down workers\n",
            "W1117 11:40:56.835000 4791 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4814 closing signal SIGINT\n",
            "W1117 11:40:56.835000 4791 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4815 closing signal SIGINT\n",
            "W1117 11:40:56.835000 4791 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4816 closing signal SIGINT\n",
            "W1117 11:40:56.836000 4791 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 4817 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 28, in <module>\n",
            "    from datasets import load_dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n",
            "    from .arrow_dataset import Dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 63, in <module>\n",
            "    from huggingface_hub import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py\", line 547, in __getattr__\n",
            "    submod = importlib.import_module(submod_path)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 28, in <module>\n",
            "    from datasets import load_dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n",
            "    from .arrow_dataset import Dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 63, in <module>\n",
            "    from huggingface_hub import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py\", line 547, in __getattr__\n",
            "    submod = importlib.import_module(submod_path)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 46, in <module>\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 46, in <module>\n",
            "    import requests\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/__init__.py\", line 164, in <module>\n",
            "    import requests\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/__init__.py\", line 164, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 11, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 11, in <module>\n",
            "        from . import sessionsfrom . import sessions\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 15, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 15, in <module>\n",
            "        from .adapters import HTTPAdapterfrom .adapters import HTTPAdapter\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 81, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 81, in <module>\n",
            "    _preloaded_ssl_context.load_verify_locations(\n",
            "    KeyboardInterrupt_preloaded_ssl_context.load_verify_locations(\n",
            "\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 28, in <module>\n",
            "    from datasets import load_dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n",
            "    from .arrow_dataset import Dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 63, in <module>\n",
            "    from huggingface_hub import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py\", line 547, in __getattr__\n",
            "    submod = importlib.import_module(submod_path)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 46, in <module>\n",
            "    import requests\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/__init__.py\", line 164, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 11, in <module>\n",
            "    from . import sessions\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 15, in <module>\n",
            "    from .adapters import HTTPAdapter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 81, in <module>\n",
            "    _preloaded_ssl_context.load_verify_locations(\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 28, in <module>\n",
            "    from datasets import load_dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/__init__.py\", line 17, in <module>\n",
            "    from .arrow_dataset import Dataset\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 63, in <module>\n",
            "    from huggingface_hub import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py\", line 547, in __getattr__\n",
            "    submod = importlib.import_module(submod_path)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 46, in <module>\n",
            "    import requests\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/__init__.py\", line 164, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 11, in <module>\n",
            "    from . import sessions\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 15, in <module>\n",
            "    from .adapters import HTTPAdapter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 81, in <module>\n",
            "    _preloaded_ssl_context.load_verify_locations(\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 208, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typing_extensions.py\", line 2853, in wrapper\n",
            "    return arg(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 204, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launch.py\", line 189, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 260, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py\", line 137, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 696, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 855, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 4791 got signal: 2\n",
            "Map Config config/offset_map/first_offset_en.yaml\n",
            "data/text2spotasoc/entity/conll03/record.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/entity/conll03/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run3/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run3/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run3/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run3/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-40-8202_hf_models_uie-large-en_spotasoc_entity_conll03_e50_linear_lr1e-4_ls0_b32_wu0.06_n-1_RP_sn0.1_an0.1_run3/’: No such file or directory\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%env model_name=uie-large-en\n",
        "%env dataset_name=conll03\n",
        "\n",
        "! . config/data_conf/large_conll03_conf.ini && bash scripts_exp/run_exp.bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BGEpcvf7Z0Q",
        "outputId": "32b077a4-f261-42bc-b4a9-494a31f42afc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: model_name=uie-large-en\n",
            "env: dataset_name=conll03\n",
            "batch  8\n",
            "noise  0.1\n",
            "learning rate  1e-4\n",
            "warmup ratio  0.06\n",
            "label smoothing  0\n",
            "negative  -1\n",
            "Master Port: 37878\n",
            "Map Config config/offset_map/first_offset_en.yaml\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! bash run_uie_finetune.bash -v -d 0 \\\n",
        "  -b 16 \\\n",
        "  -k 3 \\\n",
        "  --lr 1e-4 \\\n",
        "  --warmup_ratio 0.06 \\\n",
        "  -i absa/14lap \\\n",
        "  --epoch 50 \\\n",
        "  --spot_noise 0.1 \\\n",
        "  --asoc_noise 0.1 \\\n",
        "  -f spotasoc \\\n",
        "  --epoch 50 \\\n",
        "  --map_config config/offset_map/closest_offset_en.yaml \\\n",
        "  -m hf_models/uie-base-en \\\n",
        "  --random_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsb_HSTvqbYs",
        "outputId": "37f5dbb5-121d-40ee-9906-e94fd1f8d2a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map Config config/offset_map/closest_offset_en.yaml\n",
            "2024-11-17 11:31:06.776742: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:31:06.795135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:31:06.816650: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:31:06.823064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:31:06.838608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:31:08.025323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   Options:\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   ModelArguments(model_name_or_path='hf_models/uie-base-en', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, from_checkpoint=False)\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   DataTrainingArguments(task='meta', dataset_name=None, dataset_config_name=None, text_column='text', record_column='record', train_file='data/text2spotasoc/absa/14lap/train.json', validation_file='data/text2spotasoc/absa/14lap/val.json', test_file='data/text2spotasoc/absa/14lap/test.json', overwrite_cache=False, preprocessing_num_workers=4, preprocess=True, preprocessed_folder=None, max_source_length=256, max_target_length=192, max_prefix_length=-1, val_max_target_length=192, pad_to_max_length=False, max_train_samples=None, max_val_samples=None, max_test_samples=None, num_beams=None, ignore_pad_token_for_loss=True, source_prefix='meta: ', meta_negative=-1, ordered_prompt=False, decoding_format='spotasoc', record_schema='data/text2spotasoc/absa/14lap/record.schema', spot_noise=0.1, asoc_noise=0.1, meta_positive_rate=1.0)\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=421,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:10 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   Training/evaluation parameters ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=421,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:10 - INFO - __main__ -   {'train': 'data/text2spotasoc/absa/14lap/train.json', 'validation': 'data/text2spotasoc/absa/14lap/val.json', 'test': 'data/text2spotasoc/absa/14lap/test.json'}\n",
            "The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 125, in resolve_trust_remote_code\n",
            "    answer = input(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 107, in _raise_timeout_error\n",
            "    raise ValueError(\n",
            "ValueError: Loading this dataset requires you to execute custom code contained in the dataset repository on your local machine. Please set the option `trust_remote_code=True` to permit loading of this dataset.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "    main()\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "    datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1853, in load_dataset_builder\n",
            "    dataset_module = dataset_module_factory(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1571, in dataset_module_factory\n",
            "    ).get_module()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 761, in get_module\n",
            "    trust_remote_code = resolve_trust_remote_code(self.trust_remote_code, self.name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 138, in resolve_trust_remote_code\n",
            "    raise ValueError(\n",
            "ValueError: The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
            "Map Config config/offset_map/closest_offset_en.yaml\n",
            "data/text2spotasoc/absa/14lap/record.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run1/’: No such file or directory\n",
            "2024-11-17 11:31:32.161734: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:31:32.178479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:31:32.198912: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:31:32.205143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:31:32.219579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:31:33.375295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   Options:\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   ModelArguments(model_name_or_path='hf_models/uie-base-en', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, from_checkpoint=False)\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   DataTrainingArguments(task='meta', dataset_name=None, dataset_config_name=None, text_column='text', record_column='record', train_file='data/text2spotasoc/absa/14lap/train.json', validation_file='data/text2spotasoc/absa/14lap/val.json', test_file='data/text2spotasoc/absa/14lap/test.json', overwrite_cache=False, preprocessing_num_workers=4, preprocess=True, preprocessed_folder=None, max_source_length=256, max_target_length=192, max_prefix_length=-1, val_max_target_length=192, pad_to_max_length=False, max_train_samples=None, max_val_samples=None, max_test_samples=None, num_beams=None, ignore_pad_token_for_loss=True, source_prefix='meta: ', meta_negative=-1, ordered_prompt=False, decoding_format='spotasoc', record_schema='data/text2spotasoc/absa/14lap/record.schema', spot_noise=0.1, asoc_noise=0.1, meta_positive_rate=1.0)\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=422,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:36 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   Training/evaluation parameters ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=422,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:36 - INFO - __main__ -   {'train': 'data/text2spotasoc/absa/14lap/train.json', 'validation': 'data/text2spotasoc/absa/14lap/val.json', 'test': 'data/text2spotasoc/absa/14lap/test.json'}\n",
            "The repository for uie_json contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/uie_json.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "    main()\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "    datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1890, in load_dataset_builder\n",
            "    builder_instance: DatasetBuilder = builder_cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 328, in __init__\n",
            "    data_files = DataFilesDict.from_patterns(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 721, in from_patterns\n",
            "    else DataFilesList.from_patterns(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 624, in from_patterns\n",
            "    resolve_pattern(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 411, in resolve_pattern\n",
            "    raise FileNotFoundError(error_msg)\n",
            "FileNotFoundError: Unable to find './data/text2spotasoc/absa/14lap/train.json'\n",
            "Map Config config/offset_map/closest_offset_en.yaml\n",
            "data/text2spotasoc/absa/14lap/record.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run2/’: No such file or directory\n",
            "2024-11-17 11:31:45.396368: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-17 11:31:45.413727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-17 11:31:45.435454: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-17 11:31:45.442003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-17 11:31:45.456929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-17 11:31:46.683755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   Options:\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   ModelArguments(model_name_or_path='hf_models/uie-base-en', config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, from_checkpoint=False)\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   DataTrainingArguments(task='meta', dataset_name=None, dataset_config_name=None, text_column='text', record_column='record', train_file='data/text2spotasoc/absa/14lap/train.json', validation_file='data/text2spotasoc/absa/14lap/val.json', test_file='data/text2spotasoc/absa/14lap/test.json', overwrite_cache=False, preprocessing_num_workers=4, preprocess=True, preprocessed_folder=None, max_source_length=256, max_target_length=192, max_prefix_length=-1, val_max_target_length=192, pad_to_max_length=False, max_train_samples=None, max_val_samples=None, max_test_samples=None, num_beams=None, ignore_pad_token_for_loss=True, source_prefix='meta: ', meta_negative=-1, ordered_prompt=False, decoding_format='spotasoc', record_schema='data/text2spotasoc/absa/14lap/record.schema', spot_noise=0.1, asoc_noise=0.1, meta_positive_rate=1.0)\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=423,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:49 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   Training/evaluation parameters ConstraintSeq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "constraint_decoding=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=0.0,\n",
            "eval_strategy=epoch,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3_log,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=eval_overall-F1,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=50.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=16,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3,\n",
            "save_better_checkpoint=False,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=423,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "start_eval_step=0,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.06,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "11/17/2024 11:31:49 - INFO - __main__ -   {'train': 'data/text2spotasoc/absa/14lap/train.json', 'validation': 'data/text2spotasoc/absa/14lap/val.json', 'test': 'data/text2spotasoc/absa/14lap/test.json'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 520, in <module>\n",
            "    main()\n",
            "  File \"/content/UIE/run_uie_finetune.py\", line 141, in main\n",
            "    datasets = load_dataset(\"uie_json.py\", data_files=data_files)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2132, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 1890, in load_dataset_builder\n",
            "    builder_instance: DatasetBuilder = builder_cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 328, in __init__\n",
            "    data_files = DataFilesDict.from_patterns(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 721, in from_patterns\n",
            "    else DataFilesList.from_patterns(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 624, in from_patterns\n",
            "    resolve_pattern(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\", line 411, in resolve_pattern\n",
            "    raise FileNotFoundError(error_msg)\n",
            "FileNotFoundError: Unable to find './data/text2spotasoc/absa/14lap/train.json'\n",
            "Map Config config/offset_map/closest_offset_en.yaml\n",
            "data/text2spotasoc/absa/14lap/record.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/entity.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/relation.schema is empty, ignore.\n",
            "data/text2spotasoc/absa/14lap/event.schema is empty, ignore.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3/eval_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3/test_preds_seq2seq.txt not found.\n",
            "\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3/eval_preds_record.txt not found.\n",
            "output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3/test_preds_record.txt not found.\n",
            "===========> AVG <===========\n",
            "find: ‘output/meta_2024-11-17-11-31-18492_hf_models_uie-base-en_spotasoc_absa_14lap_e50_linear_lr1e-4_ls0_b16_wu0.06_n-1_RP_sn0.1_an0.1_run3/’: No such file or directory\n"
          ]
        }
      ]
    }
  ]
}